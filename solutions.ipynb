{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advent of code 2021\n",
    "\n",
    "My first time entering Advent of Code. I'm pretty rusty in Python at the moment, so I have shameless copied the utility functions from Peter Norvieg's [2020 solutions](https://github.com/norvig/pytudes/blob/main/ipynb/Advent-2020.ipynb) so that my attempts will at least start off in a well structured fashion.\n",
    "\n",
    "Only entering to complete, not to get a fast time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__  import annotations\n",
    "from collections import Counter, defaultdict, namedtuple, deque\n",
    "from itertools   import permutations, combinations, product, chain, tee\n",
    "from functools   import lru_cache, reduce\n",
    "from typing      import Dict, Tuple, Set, List, Iterator, Optional, Union, NamedTuple\n",
    "\n",
    "import operator\n",
    "import math\n",
    "import ast\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peter Norveigs utilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(day: int, parser=str, sep='\\n') -> list:\n",
    "    \"Split the day's input file into sections separated by `sep`, and apply `parser` to each.\"\n",
    "    sections = open(f'data/input{day}.txt').read().rstrip().split(sep)\n",
    "    return [parser(section) for section in sections]\n",
    "     \n",
    "def do(day, *answers) -> Dict[int, int]:\n",
    "    \"E.g., do(3) returns {1: day3_1(in3), 2: day3_2(in3)}. Verifies `answers` if given.\"\n",
    "    g = globals()\n",
    "    got = []\n",
    "    for part in (1, 2):\n",
    "        fname = f'day{day}_{part}'\n",
    "        if fname in g: \n",
    "            got.append(g[fname](g[f'in{day}']))\n",
    "            if len(answers) >= part: \n",
    "                assert got[-1] == answers[part - 1], (\n",
    "                    f'{fname}(in{day}) got {got[-1]}; expected {answers[part - 1]}')\n",
    "    return got\n",
    "\n",
    "Number = Union[float, int]\n",
    "Atom = Union[Number, str]\n",
    "Char = str # Type used to indicate a single character\n",
    "\n",
    "flatten = chain.from_iterable\n",
    "\n",
    "def prod(numbers) -> Number:\n",
    "    \"The product of an iterable of numbers.\" \n",
    "    return reduce(operator.mul, numbers, 1)\n",
    "\n",
    "def atoms(text: str, ignore=r'', sep=None) -> Tuple[Union[int, str]]:\n",
    "    \"Parse text into atoms (numbers or strs), possibly ignoring a regex.\"\n",
    "    if ignore:\n",
    "        text = re.sub(ignore, '', text)\n",
    "    return tuple(map(atom, text.split(sep)))\n",
    "\n",
    "def atom(text: str) -> Union[float, int, str]:\n",
    "    \"Parse text into a single float or int or str.\"\n",
    "    try:\n",
    "        val = float(text)\n",
    "        return round(val) if round(val) == val else val\n",
    "    except ValueError:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise(iterable): # Defined in itertools in python 3.10 but I'm in 3.9\n",
    "    \"pairwise('ABCDEFG') --> AB BC CD DE EF FG\"\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 1: Sonar Sweep\n",
    "Part 1 is to compute the number of times we see an increase between elements. Itertools has a helpful _pairwise_ function that allows comparison between two adjacent elements in a list without making a full copy. Part 2 is to compute a sliding window first.. so I 'adapted' the _pairwise_ function to allow a 3-element sliding window but it's not nicely generalised to different window lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "in1: List[int] = data(1, int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day1_1(nums):\n",
    "    return sum(second > first for first,second in pairwise(nums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day1_2(nums):\n",
    "    \"Niave extension of itertools.pairwise\"\n",
    "    a, b, c = tee(nums, 3)\n",
    "    next(b, None)\n",
    "    next(c, None)\n",
    "    next(c, None)\n",
    "    moving_average = [x+y+z for x, y, z in zip(a, b, c)]\n",
    "    return day1_1(moving_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert day1_1([199, 200, 208, 210, 200, 207, 240, 269, 260, 263]) == 7\n",
    "assert day1_2([199, 200, 208, 210, 200, 207, 240, 269, 260, 263]) == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1832, 1858]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do(1, 1832, 1858)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 2: Dive!\n",
    "\n",
    "For part 1 we don't need to worry about the order of the commands (assuming that we don't need to verify that the depth is always sensible). Brute fore approach for part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Instruction = Tuple[str, int] # e.g. ('up', 1)\n",
    "Program = List[Instruction]\n",
    "\n",
    "in2: Program = data(2, atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_direction(program, direction):\n",
    "    return sum(x[1] for x in filter(lambda x: x[0]==direction, program))\n",
    "\n",
    "assert sum_direction([('down',2),('forward',7),('down',1)],\"down\") == 3\n",
    "\n",
    "def day2_1(program):\n",
    "    \"Assumes that the input is valid and we don't have to worry about the submarine trying to go above the waterline\"\n",
    "    horizontal_position = sum_direction(program,\"forward\")\n",
    "    depth = sum_direction(program,\"down\") - sum_direction(program,\"up\")\n",
    "    return depth * horizontal_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day2_2(program):\n",
    "    aim, depth, horizontal_position = 0, 0, 0\n",
    "    for command, v in program:\n",
    "        if command == \"down\":\n",
    "            aim += v\n",
    "        elif command == \"up\":\n",
    "            aim -= v\n",
    "        elif command == \"forward\":\n",
    "            depth += aim * v\n",
    "            horizontal_position += v\n",
    "        else:\n",
    "            raise Exception('Unexpected command %s',command)\n",
    "    return depth * horizontal_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1484118, 1463827010]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do(2, 1484118, 1463827010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 3: Binary Diagnostic\n",
    "Full brute force today. For part I I'm sure there must be a better way to unpack the most common element from a _Counter_ and to use the two's complement operator to compute epsilon. In part II, there must be a better way to find the most common element with a default.\n",
    "\n",
    "I might revisit  these at a later date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "in3: List(int) = data(3, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day3_1(nums):\n",
    "    nums = [list(x) for x in nums]\n",
    "    nums = list(map(list, zip(*nums)))\n",
    "    counters = [Counter(x) for x in nums]\n",
    "    gamma = \"\".join(str(x.most_common(1)[0][0]) for x in counters)\n",
    "    epsilon = \"\".join(str(x.most_common()[-1][0]) for x in counters)\n",
    "    return int(gamma,base=2) * int(epsilon, base=2)\n",
    "\n",
    "def get_rating(nums, mode):\n",
    "    ix = 0\n",
    "    while len(nums) > 1 and ix < len(nums[0]):\n",
    "        counter = Counter(x[ix] for x in nums)\n",
    "        v = counter.most_common(1)[0] if mode==\"most\" else counter.most_common()[-1]\n",
    "        if v[1]*2 == len(nums):\n",
    "            v = '1' if mode==\"most\" else '0'\n",
    "        else:\n",
    "            v = v[0]\n",
    "        nums = list(filter(lambda x: x[ix] == v,nums))\n",
    "        ix += 1\n",
    "    return nums[0]\n",
    "\n",
    "def day3_2(nums):\n",
    "    oxygen = get_rating(nums,mode=\"most\")\n",
    "    co2 = get_rating(nums,mode=\"least\")\n",
    "    return int(oxygen,base=2) * int(co2,base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2724524, 2775870]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do(3, 2724524, 2775870)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 4: Giant Squid\n",
    "I implemented a BingoBoard class on my first attempt here, but decided this was unnecessary when I revisited it. I think my runtime complexity is _O(NDB^2)_ for N boards, B elements per board and D draws because of the _is_bingo_ function, but the input is not that big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bingo_boards(line: str) -> List[int]:\n",
    "    return list(map(int,re.split(\"\\W+\",line.strip())))\n",
    "\n",
    "in4: List[int] = data(4, parse_bingo_boards, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_bingo(hits, width = 5):\n",
    "    out = any(all(hits[i:i+width]) for i in range(0,len(hits),width)) # check for complete rows\n",
    "    if not out:\n",
    "        out = any(all(hits[i:len(hits):width]) for i in range(width)) # check for complete columns\n",
    "    return out\n",
    "\n",
    "def score_bingo_board(board, draws):\n",
    "    hits = [False for x in range(len(board))]\n",
    "    bingo = False\n",
    "    for i, draw in enumerate(draws):\n",
    "        if draw in board:\n",
    "            hits[board.index(draw)] = True\n",
    "            bingo = is_bingo(hits)\n",
    "            if bingo: break\n",
    "    if bingo:\n",
    "        return (i, draw * sum(x for x, h in zip(board,hits) if not h))\n",
    "    else:\n",
    "        return (math.inf, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day4_1(boards):\n",
    "    scores = [score_bingo_board(x, boards[0]) for x in boards[1:]]\n",
    "    out = min(scores, key = lambda x: x[0])\n",
    "    return out[1]\n",
    "\n",
    "def day4_2(boards):\n",
    "    scores = [score_bingo_board(x, boards[0]) for x in boards[1:]]\n",
    "    scores = filter(lambda x: math.isfinite(x[0]), scores)\n",
    "    out = max(scores, key = lambda x: x[0])\n",
    "    return out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49860, 24628]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do(4, 49860, 24628)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 5: Hydrothermal Venture\n",
    "Part I is to count the number of overlapping points given a set of horizontal / vertical line segments. Pythons _Counter_ again was quite useful to count the number of overlaps. Part II just required an extension to _parse\\_line\\_segments_ to deal with diagonal lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line_segments(line: str) -> Tuple[int, int, int, int]:  \n",
    "    a,b,c,d = map(int,re.findall(r'[^->,\\s]+',line))\n",
    "    assert a == c or b == d or (abs(a-c) == abs(b-d)), \"Lines must be at 0, 45, 90 degrees\"\n",
    "    return (a,b,c,d)\n",
    "\n",
    "in5: Tuple[int, int, int, int] = data(5, parse_line_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_diagonal(segment):\n",
    "    a,b,c,d = segment\n",
    "    return (abs(a-c) == abs(b-d)) and not (a == c or b == d)\n",
    "\n",
    "def expand_segment(segment):\n",
    "    a,b,c,d = segment\n",
    "    if a == c:\n",
    "        x1, x2 = min(b,d), max(b, d)\n",
    "        return [(a,x) for x in range(x1,x2+1)]\n",
    "    elif b == d:\n",
    "        x1, x2 = min(a,c), max(a, c)\n",
    "        return [(x,b) for x in range(x1,x2+1)]\n",
    "    else:\n",
    "        signX = 1 if c > a else -1\n",
    "        signY = 1 if d > b else -1\n",
    "        return [(a+signX*i,b+signY*i) for i in range(abs(a-c)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day5_1(segments):\n",
    "    counter = Counter()\n",
    "    for segment in segments:\n",
    "        if not is_diagonal(segment):\n",
    "            counter.update(expand_segment(segment))\n",
    "    return sum(counter[x]>1 for x in counter)\n",
    "\n",
    "def day5_2(segments):\n",
    "    counter = Counter()\n",
    "    for segment in segments:\n",
    "        counter.update(expand_segment(segment))\n",
    "    return sum(counter[x]>1 for x in counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5167, 17604]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do(5, 5167, 17604)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 6: Lanternfish\n",
    "A question about modelling the population size of some fish, given that they reproduce every 6 days (or 8 if they are new), which lends itself nicely to recursion and the _lru\\_cache_. The grid of cached values should be only 8 * 256 for part II."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "in6: List[int] = data(6,int,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache\n",
    "def population_size(fish_timer, days):\n",
    "    step = min(days, fish_timer+1)\n",
    "    if days == 0:\n",
    "        out = 1\n",
    "    elif days >= fish_timer+1:\n",
    "        out = population_size(6, days - fish_timer - 1) + population_size(8, days - fish_timer - 1)\n",
    "    else:\n",
    "        out = population_size(fish_timer - days, 0)\n",
    "    return out\n",
    "\n",
    "assert population_size(3,3) == 1\n",
    "assert population_size(3,4) == 2\n",
    "assert population_size(3,10) == 2\n",
    "assert population_size(3,11) == 3\n",
    "assert population_size(3,13) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day6_1(fish_timers): return sum(population_size(x,80) for x in fish_timers)\n",
    "\n",
    "def day6_2(fish_timers): return sum(population_size(x,256) for x in fish_timers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[386755, 1732731810807]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do(6, 386755, 1732731810807)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 7: The Treachery of Whales\n",
    "Part I is to compute _min\\_p \\sum\\_i abs(x\\_i - p)_ and part II is to compute _min\\_p \\sum\\_i abs(x\\_i - p) * (abs(x\\_i - p)+1)/2_ for a vector _x_ of initial positions. There is probably a clever way to solve these minimization problems, however the input is not that big so I opted for the brute force approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "in7: List[int] = data(7,int,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day7_1(positions):\n",
    "    fuel = math.inf\n",
    "    for p in range(min(positions),max(positions)+1):\n",
    "        v = sum(abs(x-p) for x in positions)\n",
    "        fuel = min(v,fuel)\n",
    "    return fuel\n",
    "\n",
    "def day7_2(positions):\n",
    "    fuel = math.inf\n",
    "    for p in range(min(positions),max(positions)+1):\n",
    "        v = sum((abs(x-p)*(abs(x-p)+1))//2 for x in positions)\n",
    "        fuel = min(v,fuel)\n",
    "    return fuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[351901, 101079875]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do(7, 351901, 101079875)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 8: Seven segment search\n",
    "Labels for a 7 segment display are scrambled, and the task is to decode 4 numbers given an encoded list of numbers 0-9. Part I is relatively straight forward as you are only asked to decode numbers with a unique number of bars. For Part II I ended up with a reasonably verbose tree of if-statements to complete my 'decoder'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Display = NamedTuple(\"Display\", [('pattern', List[frozenset]), ('output', List[frozenset])])\n",
    "\n",
    "def parse_digits(line: str) -> Display:\n",
    "    line = line.split(\"|\")\n",
    "    return Display([frozenset(x) for x in re.findall(r'[^\\s]+',line[0])],[frozenset(x) for x in re.findall(r'[^\\s]+',line[1])])\n",
    "\n",
    "in8: List[Display] = data(8, parse_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day8_1(displays: List[Display]) -> int:\n",
    "    counter = Counter()\n",
    "    for display in displays:\n",
    "        counter.update(map(len,display.output))\n",
    "    return sum(counter[x] for x in [2,4,3,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_display(display: Display) -> int:\n",
    "    lens = {2:1,7:8,4:4,3:7}\n",
    "    encoder = dict()\n",
    "    for x in display.pattern:\n",
    "        if len(x) in lens:\n",
    "            encoder[lens[len(x)]] = x\n",
    "    for x in display.pattern:\n",
    "        if len(x) in lens:\n",
    "            continue\n",
    "        elif len(x) == 6 and encoder[4].issubset(x):\n",
    "            encoder[9] = x\n",
    "        elif len(x) == 6 and not encoder[1].issubset(x):\n",
    "            encoder[6] = x\n",
    "        elif len(x) == 6:\n",
    "            encoder[0] = x\n",
    "        elif len(x) == 5 and encoder[7].issubset(x):\n",
    "            encoder[3] = x\n",
    "        elif len(x) == 5 and len(x.intersection(encoder[4])) == 3:\n",
    "            encoder[5] = x\n",
    "        else:\n",
    "            encoder[2] = x\n",
    "    decoder = {v:k for k,v in encoder.items()}\n",
    "    assert all(x in decoder for x in display.pattern)\n",
    "    return int(\"\".join([str(decoder[x]) for x in display.output]))\n",
    "\n",
    "\n",
    "def day8_2(displays: List[Display]) -> int:\n",
    "    return sum(map(decode_display, displays))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[387, 986034]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do(8, 387, 986034)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 9: Smoke Basin\n",
    "Given a heatmap find points which are local minima (part I) and the size of the 'basin' around each minima (part II). My solution to part II was inspired by the expanding bubble used in Dijkstra's algorithm. I also found a use for two additional utility functions from Peter Norveigs 2020 solutions; _flatten_ and _prod_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ints(line: str) -> List[int]:\n",
    "    return list(map(int,list(line)))\n",
    "\n",
    "in9: List[List[int]] = data(9, parse_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbours(grid,x,y):\n",
    "    out = list()\n",
    "    out += [(i,y) for i in range(max(0,x-1),min(len(grid),x+2)) if not i == x]\n",
    "    out += [(x,j) for j in range(max(0,y-1),min(len(grid[0]),y+2)) if not j == y]\n",
    "    return out\n",
    "\n",
    "def is_minima(grid,x,y):\n",
    "    return all(grid[x][y] < grid[i][j] for i, j in get_neighbours(grid,x,y))\n",
    "\n",
    "def day9_1(grid):\n",
    "    return sum(1+grid[x][y] for x, y in product(range(0,len(grid)),range(0,len(grid[0]))) if is_minima(grid,x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basin_size(grid,x,y):\n",
    "    in_basin = [[False for i in range(len(grid[0]))] for j in range(len(grid))]\n",
    "    pool = {(x,y)}\n",
    "    while pool:\n",
    "        i, j = pool.pop()\n",
    "        in_basin[i][j] = True\n",
    "        for ii, jj in get_neighbours(grid, i, j):\n",
    "            if not in_basin[ii][jj] and grid[ii][jj] < 9 and grid[ii][jj] > grid[i][j]:\n",
    "                pool.add((ii,jj))\n",
    "    return sum(flatten(in_basin))\n",
    "\n",
    "def day9_2(grid):\n",
    "    minima = [(x,y) for x, y in product(range(0,len(grid)),range(0,len(grid[0]))) if is_minima(grid,x,y)]\n",
    "    scores = [get_basin_size(grid,x,y) for x,y in minima]\n",
    "    scores.sort(reverse=True)\n",
    "    return prod(scores[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[600, 987840]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do(9, 600, 987840)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 10: Syntax Scoring\n",
    "Given a string of four different bracket types (eg. _[<>({}){}[([])<>]]_), part I is to write a simple syntax checker to determine if the string is corrupt (brackets are mismatching) and part II is to score the remaining brackets for strings that are incomplete.\n",
    "\n",
    "I decided to just parse each string from left to right, but you could possibly use recursion here too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "in10: List[str] = data(10) # eg. [<>({}){}[([])<>]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_incomplete(chars):\n",
    "    points = {')':1,']':2,'}':3,'>':4}\n",
    "    return sum((5 ** (len(chars)-1-i)) * points[x] for i, x in enumerate(chars))\n",
    "\n",
    "def check_syntax(line):\n",
    "    \"\"\"Parse line from left to right and add opening statements to a heap\"\"\"\n",
    "    open2close = {'{':'}','[':']','(':')','<':'>'}\n",
    "    points = {')':3,']':57,'}':1197,'>':25137}\n",
    "    heap = list() # small abuse: not actually a heap but will be used like one\n",
    "    is_corrupted, score = False, 0\n",
    "    for i in range(len(line)):\n",
    "        if line[i] in open2close: \n",
    "            heap.append(line[i])\n",
    "        elif not line[i] == open2close[heap.pop()]:\n",
    "            is_corrupted, score = True, points[line[i]]\n",
    "    if not is_corrupted:\n",
    "        score = score_incomplete([open2close[x] for x in reversed(heap)])\n",
    "    return (is_corrupted, score)\n",
    "\n",
    "assert score_incomplete('])}>') == 294\n",
    "assert check_syntax('[<>[]}') == (True,1197)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day10_1(input):\n",
    "    return sum(score for is_corrupted,score in map(check_syntax,input) if is_corrupted)\n",
    "\n",
    "def day10_2(input):\n",
    "    scores = sorted([score for is_corrupted,score in map(check_syntax,input) if not is_corrupted])\n",
    "    return scores[len(scores)//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[388713, 3539961434]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do(10, 388713, 3539961434)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 11: Dumbo Octopus\n",
    "The questions is as follows: consider a 10x10 grid of _Dumbo Octopuses_ which flash once their internal timer reaches a value of ten. The goal is to simulate the behaviour of the grid, and the catch is that when one ocotopus flahes it causes the timer of all neighbouring octupuses to incremement too.\n",
    "\n",
    "The interaction between octopuses meant I couldn't see any analytic methods to compute this, so I just simulated the system directly. I haven't found a pythonic way to deal with a 2D grid yet - apart from using nympy which seems like overkill for now. Here I flatten the 2D grid into a 1D vector for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "in11: List[List[int]] = data(11, parse_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbours(k,n,m):\n",
    "    row, col = k//n, k%m\n",
    "    for i in range(max(0, row-1), min(n, row+2)):\n",
    "        for j in range(max(0, col-1), min(m, col+2)):\n",
    "            if i == row and j == col: continue\n",
    "            yield i*m+j\n",
    "\n",
    "assert [x for x in get_neighbours(11,5,5)] == [5, 6, 7, 10, 12, 15, 16, 17]\n",
    "\n",
    "def print_grid(grid,n,m):\n",
    "    lines = [\"\".join(str(x%10) for x in grid[i*m:(i+1)*m]) for i in range(n)]\n",
    "    print(\"\\n\".join(x for x in lines))\n",
    "    print(\"\\n\")\n",
    "\n",
    "def simulate_step(grid, n, m):\n",
    "    grid = [x+1 for x in grid]\n",
    "    queue = [i for i, x in enumerate(grid) if (x//10) > 0]\n",
    "    done = set(queue)\n",
    "    while queue:\n",
    "        for k in get_neighbours(queue.pop(),n,m):\n",
    "            grid[k] += 1\n",
    "            if grid[k]//10 > 0 and not k in done:\n",
    "                queue.append(k)\n",
    "                done.add(k)\n",
    "    for k in done:\n",
    "        grid[k] = 0\n",
    "    return grid, len(done)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day11_1(grid, days = 100):\n",
    "    n, m = len(grid), len(grid[0])\n",
    "    grid = list(flatten(grid))\n",
    "    count = 0\n",
    "    for i in range(days):\n",
    "        grid, v = simulate_step(grid, n, m)\n",
    "        count += v\n",
    "    return count\n",
    "\n",
    "def day11_2(grid):\n",
    "    n, m = len(grid), len(grid[0])\n",
    "    grid = list(flatten(grid))\n",
    "    v, i = None, 0\n",
    "    while not v == len(grid):\n",
    "        grid, v = simulate_step(grid, n, m)\n",
    "        i += 1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1642, 320]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do(11, 1642, 320)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 12: Passage Pathing\n",
    "Count the number of valid paths in an undirected graph where no repeat visits (part I) or only 1 repeat visit (part II) is allowed to 'small' nodes. Nodes are small if the key is entirely lower case, and the input graph is constructed such that cycles are not possible (at least, given the constraints from part I/II). I used depth first search to explicitly define all valid paths and then returned the count of these.\n",
    "\n",
    "This works well enough, but is very slow for part II (10 seconds!).. possibly creating a new list each time I extend an existing path is slow and I could jut maintain the count of unique paths within the dpeth first search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Edge = Tuple[str,str]\n",
    "\n",
    "def parse_path(line: str) -> Edge:\n",
    "    return atoms(line,sep=\"-\")\n",
    "\n",
    "in12: List(Edge) = data(12, parse_path)\n",
    "assert all(x in flatten(in12) for x in ['start','end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edges_to_adjacency_table(edges:  List[str]):\n",
    "    adj = defaultdict(list)\n",
    "    for edge in edges:\n",
    "        adj[edge[0]].append(edge[1])\n",
    "        adj[edge[1]].append(edge[0])\n",
    "    return adj\n",
    "\n",
    "def path_is_valid(path: List[str], max_small_cave_repeats: int = 0) -> bool:\n",
    "    count = Counter(filter(str.islower,path))\n",
    "    return count[\"start\"] == 1 and all([x <= 2 for x in count.values()]) and sum([x>1 for x in count.values()]) <= max_small_cave_repeats\n",
    "\n",
    "assert     path_is_valid([\"start\"],0)\n",
    "assert not path_is_valid([\"start\",\"a\",\"a\"],0)\n",
    "assert     path_is_valid([\"start\",\"a\",\"a\",\"b\"],1)\n",
    "assert not path_is_valid([\"start\",\"a\",\"a\",\"b\",\"b\"],1)\n",
    "assert not path_is_valid(['start', 'dc', 'DG', 'dc', 'DG', 'dc'],1)\n",
    "\n",
    "def dfs(path, adj, max_small_cave_repeats):\n",
    "    current = path[-1]\n",
    "    if current == \"end\":\n",
    "        return [path]\n",
    "    else:\n",
    "        out = []\n",
    "        for k in adj[current]:\n",
    "            new = [*path,k]\n",
    "            if path_is_valid(new, max_small_cave_repeats):\n",
    "                out += dfs(new, adj, max_small_cave_repeats)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day12_1(input):\n",
    "    paths = dfs([\"start\"],edges_to_adjacency_table(input),0)\n",
    "    return len(paths)\n",
    "\n",
    "def day12_2(input):\n",
    "    paths = dfs([\"start\"],edges_to_adjacency_table(input),1)\n",
    "    return len(paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4241, 122134]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do(12, 4241, 122134)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 13: Transparent Origami\n",
    "Annoyingly this is not right and I haven't yet worked out what the problem is. TBC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Point = NamedTuple(\"Point\", [('x', int), ('y', int)])\n",
    "Fold  = NamedTuple(\"Fold\",  [('axis', int), ('v', int)])\n",
    "Instructions = NamedTuple(\"Instructions\", [('points',List[Point]),('folds',List[Fold])])\n",
    "\n",
    "def parse_instructions(input: List[str]) -> Instructions:\n",
    "    assert len(input) == 2\n",
    "    points = [Point(*map(int,line.split(','))) for line in input[0].splitlines()]\n",
    "    folds = [re.findall(r'(\\w)=(\\d+)',line)[0] for line in input[1].splitlines()]\n",
    "    folds = [Fold(0 if ax=='x' else  1,int(v)) for ax,v in folds]\n",
    "    return Instructions(points,folds)\n",
    "\n",
    "in13: List[str] = data(13,sep=\"\\n\\n\")\n",
    "in13 = parse_instructions(in13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflect(p: Point, fold: Fold):\n",
    "    vals = list(p)\n",
    "    vals[fold.axis] = vals[fold.axis] if vals[fold.axis] < fold.v else vals[fold.axis] - 2*(vals[fold.axis] - fold.v) # (fold.v - (vals[fold.axis] % fold.v)) % fold.v\n",
    "    return Point(*vals)\n",
    "\n",
    "def day13_1(instructions) -> int:\n",
    "    points = instructions.points\n",
    "    for fold in instructions.folds:\n",
    "        points = [reflect(p,fold) for p in points] \n",
    "    return len(set(points))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[104]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 14: Extended Polymerization\n",
    "Given an initial string (eg. _NNCB_) we are given a list of pair-insertion rules to extend the string. For example:\n",
    "1. NN -> NCN\n",
    "2. NC -> NBN\n",
    "\n",
    "The hard bit is that these insertion rules need to be applied simultaneously and using over lapping windows, and the length of the string grows quite quickly. I initially tried to compute this directly (ie using the python _re.sub_ function to perform regex replacements), but this was too slow for part (II)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Instructions = NamedTuple(\"Instructions\", [('template',str),('patterns',List[Tuple[str,str]])])\n",
    "\n",
    "def parse_instructions(input: List[str]) -> Instructions:\n",
    "    assert len(input) == 2\n",
    "    patterns = [re.findall(r'(\\w+) -> (\\w+)',line)[0] for line in input[1].splitlines()] # eg. ('NN','B')\n",
    "    return Instructions(input[0],patterns)\n",
    "\n",
    "in14: List[str] = data(14,sep=\"\\n\\n\")\n",
    "in14 = parse_instructions(in14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mutate_polymer(template,rules,repeats):\n",
    "    rules = {k:v for k,v in rules} # insertion rules\n",
    "    counts = Counter([template[i:i+2] for i in range(len(template)-1)]) # counts of pairs of letter\n",
    "    for j in range(repeats):\n",
    "        new = Counter()\n",
    "        for pair, count in counts.items():\n",
    "            if pair in rules:\n",
    "                new += Counter({pair[0]+rules[pair]:count, rules[pair]+pair[1]:count})\n",
    "            else:\n",
    "                new += Counter({pair:count})\n",
    "        counts = new\n",
    "    res = reduce(operator.add,[Counter({k[0]:v}) for k,v in counts.items()]) # single letter counts\n",
    "    res += Counter(template[len(template)-1])\n",
    "    return res\n",
    "\n",
    "assert mutate_polymer('NNCB',[('NN','C'),('NC','B'),('CB','H')],1) == Counter('NCNBCHB')\n",
    "\n",
    "def day14_1(instructions,repeats=10):\n",
    "    counts = mutate_polymer(instructions.template,instructions.patterns,repeats)\n",
    "    v = counts.most_common()\n",
    "    return v[0][1] - v[-1][1]\n",
    "\n",
    "def day14_2(instructions):  return day14_1(instructions,40)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2010, 2437698971143]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do(14, 2010, 2437698971143)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 16: Packet Decoder\n",
    "'Packets' of information are provided in compressed form as a hexadecimal string. Broadly speaking there are two types of packets:\n",
    "1. Literal packets; which contain (verson-number, packet-id, integer)\n",
    "2. Operator packets; which contain (version-number, packet-id, sub-packet-meta-info, sub-packets)\n",
    "\n",
    "Because operator packets contain sub-packets within them, this becomes a recursive structure which can be translated into basic mathetical expressions. To answer the question one must decode the hexadecimal string properly and then parse the recursive packet structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_bin(x):\n",
    "    n = len(x)\n",
    "    x = bin(int(x,16))[2:]\n",
    "    return '0'*(4*n - len(x)) + x # pad leading zeros\n",
    "\n",
    "in16: str = data(16,hex_to_bin,sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_literal(y):\n",
    "    i, isLast, value = 0, False, []\n",
    "    while not isLast:\n",
    "        isLast = y[i] == '0'\n",
    "        value.append(y[i+1:i+5])\n",
    "        i += 5\n",
    "    value = int(\"\".join(value),2)\n",
    "    return value, i\n",
    "\n",
    "def parse_operator(y):\n",
    "    i, vals = 1, []\n",
    "    if y[0] == '0': # 15 bits containing length of sub-packet\n",
    "        l, i = int(y[i:i+15],2), 16\n",
    "        while i < 16+l:\n",
    "            [v,packetEnd] = parse_packet(y[i:])\n",
    "            i += packetEnd\n",
    "            vals.append(v)        \n",
    "    elif y[0] == '1': # 11 bits representing number of sub-packets\n",
    "        n, i = int(y[i:i+11],2), 12\n",
    "        for _ in range(n):\n",
    "            [v,packetEnd] = parse_packet(y[i:])\n",
    "            i += packetEnd\n",
    "            vals.append(v)\n",
    "    else:\n",
    "        raise Exception('Unexpected packet length ID %s',y[0])\n",
    "    return vals, i\n",
    "\n",
    "def parse_packet(y):\n",
    "    version, id = int(y[:3],2), int(y[3:6],2)\n",
    "    if id == 4:\n",
    "        out, ix_end = parse_literal(y[6:])\n",
    "    else:\n",
    "        out, ix_end = parse_operator(y[6:])\n",
    "    return (version, id, out), 6+ix_end\n",
    "\n",
    "assert parse_packet(hex_to_bin('D2FE28'))[0]         == (6,4,2021)\n",
    "assert parse_packet(hex_to_bin('38006F45291200'))[0] == (1, 6, [(6, 4, 10), (2, 4, 20)])\n",
    "assert parse_packet(hex_to_bin('EE00D40C823060'))[0] == (7, 3, [(2, 4, 1), (4, 4, 2), (1, 4, 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_version_nums(packets):\n",
    "    if type(packets[2]) is list:\n",
    "        return packets[0] + sum(map(sum_version_nums,packets[2]))\n",
    "    else:\n",
    "        return packets[0]\n",
    "\n",
    "def evaluate_packets(packets):\n",
    "    assert len(packets) == 3\n",
    "    id, subs = packets[1], packets[2]\n",
    "    if id in [5,6,7]:\n",
    "        assert len(subs) == 2\n",
    "    if id == 0:   fn = operator.add\n",
    "    elif id == 1: fn = operator.mul\n",
    "    elif id == 2: fn = min\n",
    "    elif id == 3: fn = max\n",
    "    elif id == 4: # literal\n",
    "        return packets[2]\n",
    "    elif id == 5: fn = operator.gt\n",
    "    elif id == 6: fn = operator.lt\n",
    "    elif id == 7: fn = operator.eq\n",
    "    else: raise Exception('Unexpected packet id %s',id)\n",
    "    \n",
    "    return reduce(fn,[evaluate_packets(x) for x in subs])\n",
    "\n",
    "def day16_1(input):\n",
    "    return sum_version_nums(parse_packet(input[0])[0])\n",
    "\n",
    "def day16_2(input):\n",
    "    packets = parse_packet(input[0])[0]\n",
    "    return evaluate_packets(packets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[925, 342997120375]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do(16, 925, 342997120375)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
